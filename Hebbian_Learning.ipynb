{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hebbian Learning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1birdbZrn8k34hDjl8Yuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamieBali/hopfieldSudokuSolver/blob/main/Hebbian_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hebbian Learning\n",
        "\n",
        "Following \"The Effects of Hebbian Learning on Optimisation in Hopfield Networks\" (Watson, Buckley, and Mills), I intend to implement Hebbian Learning, and attempt to scale up the solution to solve Sudoku problems."
      ],
      "metadata": {
        "id": "_EraIOS2jyGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## imports\n",
        "import random, math, pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PUDGFH2Ej4o9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n",
        "The state of a Hopfield Network consisting of N discrete states $S_i$ where $i = 1,2,...,N$ can be written as $S = (s_i,...,s_N)$\n",
        "\n",
        "$S_i(t+1) = Θ[∑_j ω_iⱼ S_i(t)]$\n",
        "<br> Where ω are the elements of the connection matrix Ω, and Θ is the Heaviside threshold function.\n",
        "\n",
        "The Hopfield network is run by repeatedly choosing a unit, $i$, uniformly at random and setting its state according to the above formula. \n",
        "\n",
        "Energy = -∑ᵢⱼωᵢⱼsᵢsⱼ\n"
      ],
      "metadata": {
        "id": "dgXKxzg_-zUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# The energy of a problem needs to be reduced. This function finds what the energy is at a given state.\n",
        "##\n",
        "def getEnergy(weights, neurones):\n",
        "  #Energy = -sum(w_ij x s_i x s_j)\n",
        "  sum = 0\n",
        "  for i in range(0,len(neurones)):\n",
        "    for j in range(0,len(neurones)):\n",
        "      sum += (weights[i][j] * neurones[i] * neurones[j])\n",
        "  energy = sum * -1\n",
        "  return energy\n",
        "\n",
        "##\n",
        "# The heaviside function is an activation function that returns +1 for values >= 0, and -1 for values less than 0\n",
        "##\n",
        "def heaviside(value):\n",
        "  if value < 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "##\n",
        "# The step function takes an index (i) for a given neurone to look at. This will be picked randomly.\n",
        "##\n",
        "def step(neurones, weights, i, size):\n",
        "  # S_i (t+1) = Θ[sum(ω_ij * S_i (t)]\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len(neurones)):\n",
        "    sum += neurones[j] * weights[i][j]\n",
        "\n",
        "  neuroneCopy = np.copy(neurones)\n",
        "  neuroneCopy[i] = heaviside(sum)\n",
        "  #neuroneCopy[i] = neuroneCopy[i] * -1\n",
        "  \n",
        "  if getBoltzmanProbability(neurones, neuroneCopy, size) == 1:\n",
        "    return neuroneCopy\n",
        "  else:\n",
        "    return neurones"
      ],
      "metadata": {
        "id": "6ztlSUtB-y7-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boltzman Machine\n",
        "\n",
        "The boltzman machine is a schocastic counterpart of the Hopfield network where a single state change is accepted probabilistically according to the change in energy it produces.\n",
        "\n",
        "We can describe such a dynamical process more generally via a probability of accepting a stochatsic change to the system state:\n",
        "\n",
        "$P[S(t+1) <- f(S(t))] = Θ'(ΔE)$ "
      ],
      "metadata": {
        "id": "En5Ko5T4cE7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P5bnFF3JcoOs"
      },
      "outputs": [],
      "source": [
        "def getBoltzmanProbability(nt, ntplus, size = 9): # refering to weights at t+1, neurones at t+1, weights at t, and neurones at t respectively\n",
        "  # t+1 - t = ΔE\n",
        "  t1 = sudokuEnergy(ntplus, size)\n",
        "  t = sudokuEnergy(nt, size)\n",
        "  Delta = t1 - t  \n",
        "\n",
        "  # below is a threshold function that takes values of 0 and 1 for negative and non-negative arguments respectively.\n",
        "  return int(Delta <= 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Restart\n",
        "\n",
        "A random restart model is an option for avoiding the trap of a local optima, so the model can be programmed to periodically take a random state configuration, $R=\\{-1|1\\}ᴺ$, every τ steps.\n",
        "\n",
        "After testing, the random restard causes too much fluctuation in this system and does not benefit the results."
      ],
      "metadata": {
        "id": "0CCzcZ00ikz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomRestart(length):\n",
        "  return random.choices([-1,1], k=length)"
      ],
      "metadata": {
        "id": "QZ5B4fkQjT5V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Construction"
      ],
      "metadata": {
        "id": "D5pGJwo7W2_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these three were taken randomly from sudoku.com\n",
        "easy = [[0,0,0,0,7,9,0,3,0],[5,0,2,0,6,1,4,7,8],[3,7,6,0,8,5,9,0,2],[0,1,7,5,0,0,8,0,0],[2,0,9,8,3,0,0,0,0],[0,0,0,0,2,0,0,4,0],[0,0,0,0,5,0,2,0,1],[0,2,3,0,0,0,0,5,4],[1,0,0,7,0,0,0,0,0]]\n",
        "medium = [[0,3,1,0,5,0,0,2,0],[0,0,0,0,0,2,9,0,5],[2,0,0,0,1,0,0,0,0],[3,5,0,0,9,0,0,7,0],[7,0,0,5,0,0,0,4,0],[0,1,0,7,0,3,2,0,0],[1,2,6,3,0,0,0,0,0],[0,9,0,8,0,5,0,0,0],[5,0,0,0,2,0,7,0,0]]\n",
        "hard = [[0,4,0,0,0,5,0,6,0],[0,0,5,4,2,0,0,0,0],[0,0,1,6,0,3,5,0,4],[0,0,0,0,0,0,7,0,0],[0,3,7,0,0,0,0,1,0],[9,0,0,0,0,4,3,5,0],[0,0,4,2,5,0,0,0,0],[0,0,0,0,0,0,0,7,6],[6,0,9,0,7,0,0,0,5]]\n",
        "\n",
        "# this is the solved version of the \"easy\" sudoku above.\n",
        "solved = [[8,4,1,2,7,9,6,3,5],[5,9,2,3,6,1,4,7,8],[3,7,6,4,8,5,9,1,2],[4,1,7,5,9,6,8,2,3],[2,5,9,8,3,4,1,6,7],[6,3,8,1,2,7,5,4,9],[7,6,4,9,5,3,2,8,1],[9,2,3,6,1,8,7,5,4],[1,8,5,7,4,2,3,9,6]]\n",
        "\n",
        "# this puzzle is taken from \"expert star sudoku,\" a book of level 6 sudoku.\n",
        "expert = [[0,0,0,0,1,0,0,0,0],[0,9,0,0,0,5,0,0,0],[5,0,0,0,7,6,0,0,0],[0,0,4,0,0,0,2,7,0],[0,2,0,0,0,0,5,0,9],[0,7,0,8,0,0,0,0,0],[0,0,1,0,0,3,0,0,0],[6,0,0,1,2,0,0,8,0],[7,8,0,0,0,0,9,0,0]]\n"
      ],
      "metadata": {
        "id": "jNL16bybW2ku"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# This converts the [0-9] construction of the puzzle into a [-1 | 1] construction which is more suitable for the network. \n",
        "###\n",
        "def networkFormat(puzzle, size):\n",
        "  neurones = []\n",
        "  for row in range(0,size):\n",
        "    for column in range(0, size):\n",
        "      temp = []\n",
        "      for x in range(0, size):\n",
        "        temp.append(-1)\n",
        "      num = puzzle[row][column]\n",
        "      if num > 0:\n",
        "        temp[num-1] = 1\n",
        "      for x in temp:\n",
        "        neurones.append(x)\n",
        "  return neurones\n",
        "\n",
        "###\n",
        "# This converts the [-1 | 1] construction of the puzzle back into a [0-9] construction so it can be read. \n",
        "###\n",
        "def readableFormat(neurones, size):\n",
        "  puzzle = []\n",
        "  temp = []\n",
        "  for x in range(0,size**2):\n",
        "    tile = neurones[x*size:((x+1)*size)]\n",
        "    found = False\n",
        "    for y in range(0,size):\n",
        "      if tile[y] == 1:\n",
        "        temp.append(y + 1)\n",
        "        found = True\n",
        "        break\n",
        "    if found == False:\n",
        "      temp.append(0)\n",
        "    if (x + 1) % size == 0:\n",
        "      puzzle.append(temp)\n",
        "      temp = []\n",
        "  return puzzle"
      ],
      "metadata": {
        "id": "mwYDpJSAaht0"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createWeights(neurones, size = 9):\n",
        "  weights = []\n",
        "  for x in range(0, len(neurones)):\n",
        "    temp = []\n",
        "    for y in range(0, len(neurones)):\n",
        "      if y == x:\n",
        "        temp.append(1)\n",
        "      else:\n",
        "        temp.append(-1)\n",
        "    weights.append(temp)\n",
        "  return weights"
      ],
      "metadata": {
        "id": "fN11qqmkpAWe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Better Energy Functions\n",
        "\n",
        "Using the hopfield energy will allow us to minimise the weight of a network, but in order to solve a puzzle we need to have our energy function represent how close the puzzle is to being solved. This *how-solved-ness* is an inverse score, such that 0 means a puzzle is perfectly solved.\n",
        "\n",
        "This energy function, like the construction functions above, is written dynamically, so we can scale the size of the puzzles.\n",
        "\n",
        "\"In principle, the original behaviour of the system need not be governed by a weight matrix, but by some arbitrary energy function, $e(S)$, which is just some function of the state.\" (Watson, Buckley, and Mills)"
      ],
      "metadata": {
        "id": "3uOmWnqEbaMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getLocation(row, column, number, size):\n",
        "  return int((column * (size ** 2)) + (row * size) + number)\n",
        "  \n",
        "\n",
        "##\n",
        "# This arbitrary energy function seeks to minimize the weight of a Sudoku problem. If the problem is perfectly solved, the energy should be 0.\n",
        "# The energy will then be affected by the learned weights matrix.\n",
        "##\n",
        "def sudokuEnergy(neurones, size = 9):\n",
        "  # For a completed \n",
        "  energy = 4*(size**2)\n",
        "\n",
        "  # sum across i for all j,k (each number appears in each row once and only once)\n",
        "  for column in range(0,size):\n",
        "    for number in range(0,size):\n",
        "      count = 0\n",
        "      for row in range(0,size):\n",
        "        if neurones[getLocation(row, column, number, size)] == 1:\n",
        "          count += 1\n",
        "      if count == 1:\n",
        "        energy -= 1\n",
        "      if count > 1:\n",
        "        energy += 50 # a rule violation should lead to a massive increase in energy so it isn't picked\n",
        "\n",
        "  # sum across j for all i,k (each number appears in each column once and only once)\n",
        "  for row in range(0,size):\n",
        "    for number in range(0,size):\n",
        "      count = 0\n",
        "      for column in range(0,size):\n",
        "        if neurones[getLocation(row, column, number, size)] == 1:\n",
        "          count += 1\n",
        "      if count == 1:\n",
        "        energy -= 1\n",
        "      if count > 1:\n",
        "        energy += 50\n",
        "\n",
        "  # sum across k for all i,j (each tile contains only one number)\n",
        "  for row in range(0,size):\n",
        "    for cloumn in range(0,size):\n",
        "      count = 0\n",
        "      for number in range(0,size):\n",
        "        if neurones[getLocation(row, column, number, size)] == 1:\n",
        "          count += 1\n",
        "      if count == 1:\n",
        "        energy -= 1\n",
        "      if count > 1:\n",
        "        energy += 50\n",
        "\n",
        "  # sum across i,j,k for each sub-grid on the board (each number appears in each sub-grid once and only once)\n",
        "  temp = int(math.sqrt(size))\n",
        "  for rowitt in range(0,temp):               # these row and cloumn itterators allows each individual sub-grid to be searched, and allows for easy grid size change\n",
        "    for columnitt in range(0,temp):\n",
        "      for number in range(0, size):\n",
        "        sum = 0\n",
        "        for row in range(0,temp):\n",
        "          for column in range(0,temp):\n",
        "            if neurones[getLocation((rowitt * temp) + row, (columnitt * temp) + column, number, size)] == 1:\n",
        "              sum += 1\n",
        "        if sum == 1:\n",
        "          energy -= 1\n",
        "        if sum > 1:\n",
        "          energy += 50\n",
        "  #if energy == 0:    # this is purely for debugging purposes.\n",
        "  #  print(\"SOLVED!\")\n",
        "  \n",
        "  return energy"
      ],
      "metadata": {
        "id": "IdkBf7rIbZSS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theta Values\n",
        "\n",
        "We can use theta as a value to represent given values at the start of the puzzle. We don't want these theta values to be changed, as they act as the constraints of the puzzle. We have 2 options for theta values - we can either update the neurones to factor in the theta values after any changes, or at the end of a relaxation period, or we can put in a prevention measure to stop the theta values from being changed in the first place. We will implement the latter solution."
      ],
      "metadata": {
        "id": "0A9Z5ZW1uc-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getThetaValues(neurones):\n",
        "  theta = []\n",
        "  for num, value in enumerate(neurones):\n",
        "    if value == 1:\n",
        "      theta.append(num)\n",
        "  return theta\n",
        "\n",
        "###\n",
        "# We will construct a system to apply theta values, though we should not need to use it.\n",
        "###\n",
        "def applyTheta(neurones, theta, size):\n",
        "  newNeurones = np.copy(neurones)\n",
        "  for value in theta:\n",
        "    flr = math.floor(value/size)      # by looking at the floor of val/size, we can make the 9 values to represent a tile equal -1\n",
        "    for num in range(0, size):\n",
        "      newNeurones[flr+num] = -1\n",
        "    newNeurones[value] = 1            # we then set the correct tile to 1, establishing theta.\n",
        "  return newNeurones"
      ],
      "metadata": {
        "id": "cTFQeu9nud3m"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Testing\n",
        "\n",
        "In order to test that the network is functioning, we have run the network on a 4x4 sudoku, in an attempt to find a solution to an easier puzzle. The network thus far is functionally a bit-flip algorithm with a simple activation function to only allow moves that would lower the overall energy."
      ],
      "metadata": {
        "id": "PiQgQNvJbRw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "four = [[0,3,4,0],[4,0,0,2],[1,0,0,3],[0,2,1,0]]\n",
        "_pandasData = []"
      ],
      "metadata": {
        "id": "dfOU8Fdcp_kF"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runNetwork(puzzle, size, relaxation, epochs, verbose = False):\n",
        "  neurones = networkFormat(puzzle, size)\n",
        "  weights = createWeights(neurones, size)\n",
        "  theta = getThetaValues(neurones)\n",
        "\n",
        "  start = np.copy(neurones)\n",
        "  bestEnergy = 10000\n",
        "  bestNeurones = []\n",
        "\n",
        "  for epoch in range(0, epochs):\n",
        "    print(epoch)\n",
        "    neurones = np.copy(start)\n",
        "    for x in range(0,relaxation):\n",
        "      i = random.randint(0,len(neurones)-1)\n",
        "      if i in theta:          # this prevents any changes happening to the theta values in the network, ensuring the initial values are not modulated\n",
        "        continue\n",
        "      neurones = step(neurones, weights, i, size)\n",
        "      if verbose and x % 10 == 0:\n",
        "        print(readableFormat(neurones, size))\n",
        "        print(sudokuEnergy(neurones, size))\n",
        "      \n",
        "    if sudokuEnergy(neurones, size) < bestEnergy:\n",
        "      bestEnergy = sudokuEnergy(neurones,size)\n",
        "      bestNeurones = neurones\n",
        "    \n",
        "    _pandasData.append(sudokuEnergy(neurones,size))\n",
        "    weights = updateWeights(weights, neurones) # we only run this at the end of each relaxation period.\n",
        "      \n",
        "\n",
        "  return bestNeurones"
      ],
      "metadata": {
        "id": "6uFpHrbXpFyV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hebbian Learning\n",
        "\n",
        "By combining the functions written previously with a Hebbian Learning mechanism, we can update the weights of the network as we tend towards a solution. We want to update the weights with this system before we perform the random restart function, but only at the end of relaxation."
      ],
      "metadata": {
        "id": "yRoStfdGkeUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def updateWeights(weights, neurones, delta = 0.1): # where this delta value is a learning rate.\n",
        "  for i in range(0, len(neurones)):\n",
        "    for j in range(0, len(neurones)):\n",
        "      if not(i == j) and neurones[i] == 1 and neurones[j] == 1:\n",
        "        weights[i][j] += delta\n",
        "  return weights"
      ],
      "metadata": {
        "id": "qNowB5Drklcu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hebbian Testing\n",
        "\n",
        "With the hebbian learning system implemented, we should see a general decrease in the energy between epochs, as the updated energies should allow the network to more quickly reach an optima.\n",
        "\n",
        "In order to test this, we will run a 9x9 sudoku through the network, running for 250 steps, over 100 epochs."
      ],
      "metadata": {
        "id": "SNJ9Frp_z3cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_pandasData = []\n",
        "neurones = runNetwork(easy, 9, 1000, 300, False)\n",
        "_pandasData"
      ],
      "metadata": {
        "id": "xPbBGh74z29R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}